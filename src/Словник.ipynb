{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практична робота 1 : створення словника"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Done by Yuliia Hetman, SHI-2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вхідні текстові файли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для цього завдання я вирішила обрати твори українських класиків:\n",
    "1.  -rw-rw-r-- 1 yhetman  41K  Intermezzo.txt\n",
    "2.  -rw-rw-r-- 1 yhetman 555K  Захар_Беркут.txt\n",
    "3.  -rw-rw-r-- 1 yhetman 990K  Земля.txt\n",
    "4.  -rw-rw-r-- 1 yhetman  51K  Зів'яле_листя.txt\n",
    "5.  -rw-rw-r-- 1 yhetman 472K  Кайдашева_сім'я.txt\n",
    "6.  -rw-rw-r-- 1 yhetman  33K  Камінний_хрест.txt\n",
    "7.  -rw-rw-r-- 1 yhetman 167K  Климко.txt\n",
    "8.  -rw-rw-r-- 1 yhetman 937K  Кобзар.txt\n",
    "9.  -rw-rw-r-- 1 yhetman 153K  Лісова_пісня.txt\n",
    "10. -rw-rw-r-- 1 yhetman 141K  Мартин_Боруля.txt\n",
    "11. -rw-rw-r-- 1 yhetman 261K  Маруся_Чурай.txt\n",
    "12. -rw-rw-r-- 1 yhetman 173K  Мина_Мазайло.txt\n",
    "13. -rw-rw-r-- 1 yhetman 914K  Місто.txt\n",
    "14. -rw-rw-r-- 1 yhetman 834K  Тигролови.txt\n",
    "15. -rw-rw-r-- 1 yhetman 170K  Тіні_забутих_предків.txt\n",
    "16. -rw-rw-r-- 1 yhetman 1,2M  Хіба_ревуть_воли_як_ясла_повні.txt\n",
    "17. -rw-rw-r-- 1 yhetman 584K  Чорна_Рада.txt\n",
    "18. -rw-rw-r-- 1 yhetman  50K  Я_романтика.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При створені словника мною були знехтувані пунктуаційні та інші розділові знаки (крім апострофа). Також були прибрані всі цифри, що здебільшого використовувались для позначення дат. Зайві білі знаки та табуляція були також вирізані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, json\n",
    "from string import digits\n",
    "\n",
    "def delete_sings_digits(content):\n",
    "    punc = '''!()-[]{};:\"\\,«»<>./?@#$%—…^&*_~'''\n",
    "    for ele in content:\n",
    "        if ele in punc:\n",
    "            content = content.replace(ele, \"\")\n",
    "    table = str.maketrans('', '', digits)\n",
    "    content = content.translate(table)\n",
    "    return content\n",
    "\n",
    "\n",
    "def create_vocabulary(content):    \n",
    "    raw_content = delete_sings_digits(content)\n",
    "    vocab = [i.lower() for i in raw_content.split() if i != '']\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def read_books(dirname='../books/'):\n",
    "    books = os.listdir(dirname)\n",
    "    vocabulary = list()\n",
    "    dictionary = dict()\n",
    "    memory = 0\n",
    "    for book in books:\n",
    "        with open(dirname + book, 'r', encoding='utf-8') as file:\n",
    "            text = create_vocabulary(file.read())\n",
    "            dictionary[book] = text\n",
    "            vocabulary += text\n",
    "        memory += os.stat(dirname + book).st_size\n",
    "    return memory, vocabulary, dictionary\n",
    "\n",
    "memory, vocabulary, dictionary = read_books()\n",
    "unique = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size : 7.5 MB\n",
      "Total number of words : 709181\n",
      "Total number of tokens : 94971\n"
     ]
    }
   ],
   "source": [
    "print(f'Total vocabulary size : { round((memory / (1024 * 1024)),1)} MB')\n",
    "print(f'Total number of words : {len(vocabulary)}')\n",
    "print(f'Total number of tokens : {len(unique)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size is: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "with open('vocabulary.txt', 'w') as file:\n",
    "    for i in vocabulary:\n",
    "        file.write(i + \"\\n\")\n",
    "    \n",
    "size = os.stat('vocabulary.txt').st_size\n",
    "\n",
    "print(f'File size is: {round((size/ (1024 * 1024)), 1)} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON-file size is: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "with open('vocabulary.json', 'w') as file:\n",
    "    json.dump(dictionary, file, ensure_ascii=False)\n",
    "    \n",
    "size = os.stat('vocabulary.json').st_size\n",
    "print(f'JSON-file size is: {round((size/ (1024 * 1024)), 1)} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
