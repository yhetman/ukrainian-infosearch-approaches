{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuterm Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made By Yuliia Hetman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words : 708449\n",
      "Total number of tokens : 94292\n",
      "CPU times: user 640 ms, sys: 394 ms, total: 1.03 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocessing import Pool\n",
    "import re, os, json\n",
    "from string import digits\n",
    "import pandas as pd\n",
    "\n",
    "docIDs = list(range(0, 18))\n",
    "\n",
    "\n",
    "def isUkrainian(word):\n",
    "    ukrainian = [96, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1100, 1102, 1103, 1108, 1110, 1111, 1169, 8217]\n",
    "    for l in word:\n",
    "        if ord(l) not in ukrainian:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_vocabulary(vocabulary):\n",
    "        return [k + '$' for k in set(vocabulary) if isUkrainian(k) == True]\n",
    "        \n",
    "def delete_sings_digits(content):\n",
    "    punc = '''!()-'”№[]{};:\"\\,“«»<>./?@#$%—…^&*_~|–abcdefghijklmnoqprstuvwxyz'''\n",
    "    content = \"\".join([ele for ele in content.lower() if ele not in punc])\n",
    "    table = str.maketrans('', '', digits)\n",
    "    content = content.translate(table)\n",
    "    return content\n",
    "\n",
    "\n",
    "def create_vocabulary(content):    \n",
    "    raw_content = delete_sings_digits(content)\n",
    "    vocab = [i.lower() for i in raw_content.split() if i != '']\n",
    "    return vocab\n",
    "\n",
    "def read_book(book):\n",
    "    dirname='../books/'\n",
    "    with open(dirname + book, 'r', encoding='utf-8') as file:\n",
    "        text = create_vocabulary(file.read())\n",
    "    return text\n",
    "\n",
    "        \n",
    "def get_vocabulary(dirname='../books/'):\n",
    "    books = os.listdir(dirname)\n",
    "    vocabulary = list()\n",
    "    dictionary = dict()\n",
    "    memory = 0\n",
    "    with Pool(8) as p:\n",
    "        vocabul = p.map(read_book, books)\n",
    "    for i, book in enumerate(books):\n",
    "        dictionary[book.replace('.txt', '')] = vocabul[i]\n",
    "        vocabulary += vocabul[i]\n",
    "        memory += os.stat(dirname + book).st_size\n",
    "    return memory, vocabulary, dictionary\n",
    "\n",
    "\n",
    "memory, vocabulary, dictionary = get_vocabulary()\n",
    "print(f'Total number of words : {len(vocabulary)}')\n",
    "print(f'Total number of tokens : {len(set(vocabulary))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['грубший$', 'молоді$', 'кармазинова$', 'славніший$', 'помічаєш$']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = check_vocabulary(vocabulary)\n",
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 491 ms, sys: 150 ms, total: 641 ms\n",
      "Wall time: 796 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "def create_indexes(word):\n",
    "    arr = list()\n",
    "    length = len(word)\n",
    "    for i in range(length):\n",
    "        arr.append(word[i:length] + word[:i])\n",
    "    return arr\n",
    "        \n",
    "def create_permuterm(vocabulary):\n",
    "    permuterm = list()\n",
    "    with Pool(16) as p:\n",
    "        permuterm = p.map(create_indexes, vocabulary)\n",
    "    all_permterms = list(itertools.chain.from_iterable(permuterm))\n",
    "    return all_permterms\n",
    "\n",
    "res = create_permuterm(vocabulary)\n",
    "res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%% time\n",
    "\n",
    "def compare_particles(term, parts, temp=0):\n",
    "    for i in range(len(parts)):\n",
    "        ind = term.find(parts[i])\n",
    "        if temp < ind:\n",
    "            temp = ind\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def find(word, permuterms, parts):\n",
    "    similar = list()\n",
    "    for term in permuterms:\n",
    "        if word == term[:len(word)] and compare_particles(term, parts, temp=len(word) - 1) == True:\n",
    "            similar.append(term)\n",
    "        else:\n",
    "            continue\n",
    "    return similar\n",
    "\n",
    "def post_process_terms(terms):\n",
    "    beautify = list()\n",
    "    for term in terms:\n",
    "        sign = term.find('$')\n",
    "        beautify.append(term[sign + 1:] + term[:sign])\n",
    "    return beautify\n",
    "\n",
    "def search_word(string, permuterms):\n",
    "    string += '$'\n",
    "    ind = string.rfind('*')\n",
    "    jockers = string.count('*')\n",
    "    to_find = string[ind + 1:len(string)] + string[:string.find('*')]\n",
    "    if jockers > 1:\n",
    "        parts = string.split('*')\n",
    "        parts = parts[1:-1]\n",
    "    similar_terms = find(to_find, permuterms, parts)\n",
    "    beautify = post_process_terms(similar_terms)\n",
    "    return beautify\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "search_word(\"на*ри*ва*є\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
